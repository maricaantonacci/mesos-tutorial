### Hello world example

Using the web UI available on port `4400` of your remote machine, let' start our first simple job:

![](images/chronos_1.png)

The job will run a `shell` command printing `hello world` on the standard output. It will execute every 30s. Indeed if you monitor the job execution, you will see that the job will be first queued, then it will run, then will be set to `idle` till the next run after 30s.

![](images/chronos_2.png)

![](images/chronos_3.png)

Look at the Mesos web UI to see the executed tasks:

![](images/chronos_4.png)


## Chronos REST APIs

The main API endpoint are the following:

| API Endpoint     | Description                          |
| :---------- | :----------------------------------- |
| `GET` /v1/scheduler/jobs                 |  This lists all jobs. The result is that JSON contains executor, invocationCount, and schedule/parents |
| `DELETE` /v1/scheduler/jobs              |  This deletes all jobs |
| `DELETE` /v1/scheduler/task/kill/jobName |  This deletes tasks for a given job |
| `DELETE` /v1/scheduler/job/jobName       | This deletes a particular job based on jobName |
|  `PUT` /v1/scheduler/job/jobName         | This manually starts a job |
|  `POST` /v1/scheduler/iso8601            | This adds a new job. The JSON passed should contain all the information about the job |
|  `POST` /v1/scheduler/dependency         | This adds a dependent job. It takes the same JSON format as a scheduled job. However, instead of the `schedule` field, it accepts a `parents` field. |
|  `GET` /v1/scheduler/graph/dot           | This returns the dependency graph in the form of a dot file |


## Executing a job in a Docker container

This time we will be using the REST API to submit the job. The endpoint to use is `/v1/scheduler/iso8601` and we will configure the job schedule so that it runs just one time (`R1//PT30s`):

Save the following json in a file with name `job.json`:

```bash
{
  "schedule": "R1//PT1M",
  "name": "dockerjob",
  "container": {
    "type": "DOCKER",
    "image": "ubuntu:latest"
  },
  "cpus": "0.1",
  "mem": "128",
  "command": "echo $(date)"
}

```

Then run the following command:

```bash
curl -i -H 'Content-Type: application/json' http://127.0.0.1:4400/v1/scheduler/iso8601 -d@job.json
```

If it works fine, you will get `204` response code:

```bash
HTTP/1.1 204 No Content
Date: Tue, 15 Jun 2021 22:42:49 GMT
Access-Control-Allow-Origin: *
Content-Type: application/json
Server: Jetty(9.3.z-SNAPSHOT)
```

Look at the web UI and see what happens. The job will run only once, then it will be disabled:

![](images/chronos_5.png)

## Using URIs field to download resources

In the following example we will run a simple analysis job on an input dataset.

We will use a custom docker image derived from python:3 including some python libraries. Here is the dockerfile:

```bash
FROM python:3
RUN pip install scipy numpy matplotlib pandas sklearn
```

Push the image on docker hub and then use the `uris` field to download the python script [`dataset_analysis.py`](https://raw.githubusercontent.com/iotwins-demo/demo_m19/main/src/dataset_analysis.py) to be executed and the dataset [`iris.csv`](https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv):

```bash
{
  "schedule": "R1//PT1M",
  "name": "analysis-job",
  "container": {
    "type": "DOCKER",
    "image": "marica/demo-corso:latest"
  },
  "cpus": "1",
  "mem": "512",
  "retries": 3,
  "uris": [ "https://raw.githubusercontent.com/iotwins-demo/demo_m19/main/src/dataset_analysis.py", "https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv"],
  "command": "cd $MESOS_SANDBOX; python3 dataset_analysis.py iris.csv ./"
}
```

![](images/job_1.png)

Go to the Mesos UI and access the job sandbox. 

![](images/job_2.png)

You will see the required files being downloaded:

![](images/job_3.png)

and after few moments the outputs generated by the job will appear:

![](images/job_4a.png)

![](images/job_4.png)
