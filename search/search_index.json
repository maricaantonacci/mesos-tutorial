{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The main goal of this tutorial is to learn the basic concepts on how to use a Mesos cluster and its frameworks Marathon and Chronos. Get started","title":"Home"},{"location":"chronos/","text":"Hello world example \u00b6 Using the web UI available on port 4400 of your remote machine, let' start our first simple job: The job will run a shell command printing hello world on the standard output. It will execute every 30s. Indeed if you monitor the job execution, you will see that the job will be first queued, then it will run, then will be set to idle till the next run after 30s. Look at the Mesos web UI to see the executed tasks: Chronos REST APIs \u00b6 The main API endpoint are the following: API Endpoint Description GET /v1/scheduler/jobs This lists all jobs. The result is that JSON contains executor, invocationCount, and schedule/parents DELETE /v1/scheduler/jobs This deletes all jobs DELETE /v1/scheduler/task/kill/jobName This deletes tasks for a given job DELETE /v1/scheduler/job/jobName This deletes a particular job based on jobName PUT /v1/scheduler/job/jobName This manually starts a job POST /v1/scheduler/iso8601 This adds a new job. The JSON passed should contain all the information about the job POST /v1/scheduler/dependency This adds a dependent job. It takes the same JSON format as a scheduled job. However, instead of the schedule field, it accepts a parents field. GET /v1/scheduler/graph/dot This returns the dependency graph in the form of a dot file Executing a job in a Docker container \u00b6 This time we will be using the REST API to submit the job. The endpoint to use is /v1/scheduler/iso8601 and we will configure the job schedule so that it runs just one time ( R1//PT30s ): Save the following json in a file with name job.json : { \"schedule\" : \"R1//PT1M\" , \"name\" : \"dockerjob\" , \"container\" : { \"type\" : \"DOCKER\" , \"image\" : \"ubuntu:latest\" } , \"cpus\" : \"0.1\" , \"mem\" : \"128\" , \"command\" : \"echo $( date ) \" } Then run the following command: curl -i -H 'Content-Type: application/json' http://127.0.0.1:4400/v1/scheduler/iso8601 -d@job.json If it works fine, you will get 204 response code: HTTP/1.1 204 No Content Date: Tue, 15 Jun 2021 22 :42:49 GMT Access-Control-Allow-Origin: * Content-Type: application/json Server: Jetty ( 9 .3.z-SNAPSHOT ) Look at the web UI and see what happens. The job will run only once, then it will be disabled: Using URIs field to download resources \u00b6 In the following example we will run a simple analysis job on an input dataset. We will use a custom docker image derived from python:3 including some python libraries. Here is the dockerfile: FROM python:3 RUN pip install scipy numpy matplotlib pandas sklearn Push the image on docker hub and then use the uris field to download the python script dataset_analysis.py to be executed and the dataset iris.csv : { \"schedule\" : \"R1//PT1M\" , \"name\" : \"analysis-job\" , \"container\" : { \"type\" : \"DOCKER\" , \"image\" : \"marica/demo-corso:latest\" } , \"cpus\" : \"1\" , \"mem\" : \"512\" , \"retries\" : 3 , \"uris\" : [ \"https://raw.githubusercontent.com/iotwins-demo/demo_m19/main/src/dataset_analysis.py\" , \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\" ] , \"command\" : \"cd $MESOS_SANDBOX ; python3 dataset_analysis.py iris.csv ./\" } Go to the Mesos UI and access the job sandbox. You will see the required files being downloaded: and after few moments the outputs generated by the job will appear: Execute a job dependency chain \u00b6 The web UI allows to add a dependent job clicking on + ADD JOB -> dependent . As you can see you will be asked to choose a parent job: In the following we will be using the REST API: POST /v1/scheduler/iso8601 to add a scheduled job POST /v1/scheduler/dependency to add a dependent job Let's create a first (parent) job that creates a file inside a local volume. Save the following json file as schedjob.json : { \"schedule\" : \"R1/2031-06-17T07:00:00.000Z/PT10M\" , \"name\" : \"job1\" , \"container\" : { \"type\" : \"DOCKER\" , \"image\" : \"ubuntu:latest\" , \"network\" : \"BRIDGE\" , \"volumes\" : [ { \"containerPath\" : \"/tmp/share\" , \"hostPath\" : \"/tmp\" , \"mode\" : \"RW\" } ] } , \"cpus\" : \"0.5\" , \"mem\" : \"512\" , \"command\" : \"echo Scritto da job1 > /tmp/share/job1; sleep 60;\" } Look at the schedule : we are specifying the job start in 10y...just to control the execution start... Run the following command to submit the job: curl -X POST -H 'Content-Type: application/json' http://localhost:4400/v1/scheduler/iso8601 -d@schedjob.json You will see job1 in the list of jobs and it will not start as it scheduled in 10y Now let's create the dependent job ( job2 ) that will read the file from the same local volume and will add some content. Finally, the job will copy the file in its sandbox. Save the following snippet as depjob.json : { \"name\" : \"job2\" , \"container\" : { \"type\" : \"DOCKER\" , \"image\" : \"ubuntu:latest\" , \"network\" : \"BRIDGE\" , \"volumes\" : [ { \"containerPath\" : \"/tmp/share\" , \"hostPath\" : \"/tmp\" , \"mode\" : \"RW\" } ] } , \"parents\" : [ \"job1\" ] , \"cpus\" : \"0.5\" , \"mem\" : \"512\" , \"command\" : \"echo Scritto da job2 >> /tmp/share/job1; cp /tmp/share/job1 $MESOS_SANDBOX \" } Launch the following command to add the dependent job: curl -X POST -H 'Content-Type: application/json' http://localhost:4400/v1/scheduler/dependency -d@depjob.json Now let's force job1 to start. You can use the web UI or you can make a PUT request on /v1/scheduler/job/ : curl -X PUT http://localhost:4400/v1/scheduler/job/job1 The job will start and the dependent job will run only when the parent is completed. Look at the Mesos UI and monitor the execution of the two tasks. Then enter the job2 sandbox: you will find the file job1 with the two lines written by the two jobs:","title":"Execute scheduled jobs on Chronos"},{"location":"chronos/#hello-world-example","text":"Using the web UI available on port 4400 of your remote machine, let' start our first simple job: The job will run a shell command printing hello world on the standard output. It will execute every 30s. Indeed if you monitor the job execution, you will see that the job will be first queued, then it will run, then will be set to idle till the next run after 30s. Look at the Mesos web UI to see the executed tasks:","title":"Hello world example"},{"location":"chronos/#chronos-rest-apis","text":"The main API endpoint are the following: API Endpoint Description GET /v1/scheduler/jobs This lists all jobs. The result is that JSON contains executor, invocationCount, and schedule/parents DELETE /v1/scheduler/jobs This deletes all jobs DELETE /v1/scheduler/task/kill/jobName This deletes tasks for a given job DELETE /v1/scheduler/job/jobName This deletes a particular job based on jobName PUT /v1/scheduler/job/jobName This manually starts a job POST /v1/scheduler/iso8601 This adds a new job. The JSON passed should contain all the information about the job POST /v1/scheduler/dependency This adds a dependent job. It takes the same JSON format as a scheduled job. However, instead of the schedule field, it accepts a parents field. GET /v1/scheduler/graph/dot This returns the dependency graph in the form of a dot file","title":"Chronos REST APIs"},{"location":"chronos/#executing-a-job-in-a-docker-container","text":"This time we will be using the REST API to submit the job. The endpoint to use is /v1/scheduler/iso8601 and we will configure the job schedule so that it runs just one time ( R1//PT30s ): Save the following json in a file with name job.json : { \"schedule\" : \"R1//PT1M\" , \"name\" : \"dockerjob\" , \"container\" : { \"type\" : \"DOCKER\" , \"image\" : \"ubuntu:latest\" } , \"cpus\" : \"0.1\" , \"mem\" : \"128\" , \"command\" : \"echo $( date ) \" } Then run the following command: curl -i -H 'Content-Type: application/json' http://127.0.0.1:4400/v1/scheduler/iso8601 -d@job.json If it works fine, you will get 204 response code: HTTP/1.1 204 No Content Date: Tue, 15 Jun 2021 22 :42:49 GMT Access-Control-Allow-Origin: * Content-Type: application/json Server: Jetty ( 9 .3.z-SNAPSHOT ) Look at the web UI and see what happens. The job will run only once, then it will be disabled:","title":"Executing a job in a Docker container"},{"location":"chronos/#using-uris-field-to-download-resources","text":"In the following example we will run a simple analysis job on an input dataset. We will use a custom docker image derived from python:3 including some python libraries. Here is the dockerfile: FROM python:3 RUN pip install scipy numpy matplotlib pandas sklearn Push the image on docker hub and then use the uris field to download the python script dataset_analysis.py to be executed and the dataset iris.csv : { \"schedule\" : \"R1//PT1M\" , \"name\" : \"analysis-job\" , \"container\" : { \"type\" : \"DOCKER\" , \"image\" : \"marica/demo-corso:latest\" } , \"cpus\" : \"1\" , \"mem\" : \"512\" , \"retries\" : 3 , \"uris\" : [ \"https://raw.githubusercontent.com/iotwins-demo/demo_m19/main/src/dataset_analysis.py\" , \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\" ] , \"command\" : \"cd $MESOS_SANDBOX ; python3 dataset_analysis.py iris.csv ./\" } Go to the Mesos UI and access the job sandbox. You will see the required files being downloaded: and after few moments the outputs generated by the job will appear:","title":"Using URIs field to download resources"},{"location":"chronos/#execute-a-job-dependency-chain","text":"The web UI allows to add a dependent job clicking on + ADD JOB -> dependent . As you can see you will be asked to choose a parent job: In the following we will be using the REST API: POST /v1/scheduler/iso8601 to add a scheduled job POST /v1/scheduler/dependency to add a dependent job Let's create a first (parent) job that creates a file inside a local volume. Save the following json file as schedjob.json : { \"schedule\" : \"R1/2031-06-17T07:00:00.000Z/PT10M\" , \"name\" : \"job1\" , \"container\" : { \"type\" : \"DOCKER\" , \"image\" : \"ubuntu:latest\" , \"network\" : \"BRIDGE\" , \"volumes\" : [ { \"containerPath\" : \"/tmp/share\" , \"hostPath\" : \"/tmp\" , \"mode\" : \"RW\" } ] } , \"cpus\" : \"0.5\" , \"mem\" : \"512\" , \"command\" : \"echo Scritto da job1 > /tmp/share/job1; sleep 60;\" } Look at the schedule : we are specifying the job start in 10y...just to control the execution start... Run the following command to submit the job: curl -X POST -H 'Content-Type: application/json' http://localhost:4400/v1/scheduler/iso8601 -d@schedjob.json You will see job1 in the list of jobs and it will not start as it scheduled in 10y Now let's create the dependent job ( job2 ) that will read the file from the same local volume and will add some content. Finally, the job will copy the file in its sandbox. Save the following snippet as depjob.json : { \"name\" : \"job2\" , \"container\" : { \"type\" : \"DOCKER\" , \"image\" : \"ubuntu:latest\" , \"network\" : \"BRIDGE\" , \"volumes\" : [ { \"containerPath\" : \"/tmp/share\" , \"hostPath\" : \"/tmp\" , \"mode\" : \"RW\" } ] } , \"parents\" : [ \"job1\" ] , \"cpus\" : \"0.5\" , \"mem\" : \"512\" , \"command\" : \"echo Scritto da job2 >> /tmp/share/job1; cp /tmp/share/job1 $MESOS_SANDBOX \" } Launch the following command to add the dependent job: curl -X POST -H 'Content-Type: application/json' http://localhost:4400/v1/scheduler/dependency -d@depjob.json Now let's force job1 to start. You can use the web UI or you can make a PUT request on /v1/scheduler/job/ : curl -X PUT http://localhost:4400/v1/scheduler/job/job1 The job will start and the dependent job will run only when the parent is completed. Look at the Mesos UI and monitor the execution of the two tasks. Then enter the job2 sandbox: you will find the file job1 with the two lines written by the two jobs:","title":"Execute a job dependency chain"},{"location":"intro/","text":"Description of the mini-cluster \u00b6 A typical production installation of a Mesos cluster is shown in the following diagram: For this tutorial we will be using an all-in-one installation of Mesos/Marathon/Chronos. This is the docker compose file used to setup the mini-cluster: version : '3.7' services : zookeeper : image : indigodatacloud/zookeeper expose : - 2181 environment : - MYID=1 - SERVERS=localhost volumes : - ./var/log/zookeeper:/var/log/zookeeper - ./var/lib/zookeeper:/var/lib/zookeeper mesosmaster : image : marica/mesos-master:1.11.0 ports : - 5050:5050 environment : - MESOS_HOSTNAME=192.168.28.196 - MESOS_CLUSTER=Mesos - MESOS_ZK=zk://zookeeper:2181/mesos - MESOS_LOG_DIR=/var/log/mesos - MESOS_QUORUM=1 - MESOS_WORK_DIR=/var/lib/mesos - MESOS_OFFER_TIMEOUT=30secs volumes : - ./var/log/mesos:/var/log/mesos - ./var/lib/mesos:/var/lib/mesos depends_on : - zookeeper mesosslave : image : marica/mesos-agent:1.11.0 ports : - 5051:5051 pid : host privileged : true environment : MESOS_MASTER : zk://zookeeper:2181/mesos MESOS_CONTAINERIZERS : docker,mesos MESOS_PORT : 5051 MESOS_RESOURCES : ports(*):[11000-11999] MESOS_WORK_DIR : /tmp/mesos MESOS_HOSTNAME : 192.168.28.196 volumes : - /sys/fs/cgroup:/sys/fs/cgroup - /var/run/docker.sock:/var/run/docker.sock - /tmp/mesos:/tmp/mesos - ./var/log/mesos:/var/log/mesos depends_on : - zookeeper - mesosmaster chronos : image : indigodatacloud/chronos:3.0.2_gpu ports : - 4400:4400 environment : - CHRONOS_HOSTNAME=192.168.28.196 - CHRONOS_HTTP_PORT=4400 - CHRONOS_MASTER=zk://zookeeper:2181/mesos - CHRONOS_ZK_HOSTS=zk://zookeeper:2181 - CHRONOS_ZK_PATH=/chronos/state - CHRONOS_MESOS_FRAMEWORK_NAME=chronos depends_on : - zookeeper - mesosmaster marathon : image : marica/marathon:1.8.244 ports : - 8080:8080 environment : - MARATHON_HOSTNAME=192.168.28.196 - MARATHON_HTTP_PORT=8080 - MARATHON_MASTER=zk://zookeeper:2181/mesos - MARATHON_ZK=zk://zookeeper:2181/marathon - MARATHON_FRAMEWORK_NAME=marathon depends_on : - zookeeper - mesosmaster marathon_lb : image : mesosphere/marathon-lb:v1.14.1 command : sse --marathon http://marathon:8080 --group external ports : - \"10000-10100:10000-10100\" environment : - PORTS=9090 depends_on : - marathon Start the cluster: cd /opt/mesos docker-compose up -d Check that the services are up and running: docker-compose ps Name Command State Ports ------------------------------------------------------------------------------------------------------- mesos_chronos_1 /entrypoint.sh Up 0 .0.0.0:4400->4400/tcp,:::4400->4400/tcp mesos_marathon_1 /entrypoint.sh marathon Up 0 .0.0.0:8080->8080/tcp,:::8080->8080/tcp mesos_mesosmaster_1 /entrypoint.sh /usr/sbin/m ... Up 0 .0.0.0:5050->5050/tcp,:::5050->5050/tcp mesos_mesosslave_1 /entrypoint.sh /usr/sbin/m ... Up 0 .0.0.0:5051->5051/tcp,:::5051->5051/tcp mesos_zookeeper_1 /entrypoint.sh /usr/share/ ... Up 2181 /tcp Use your browser to connect to Mesos on port 5050 of your machine: Tip Use the following command to get the ip of your VM: ip a show ens3 Open a new tab of your browser and connect to Marathon on port 8080 of your machine: Finally in another tab connect to Chronos on port 4400 of your machine:","title":"Introduction"},{"location":"intro/#description-of-the-mini-cluster","text":"A typical production installation of a Mesos cluster is shown in the following diagram: For this tutorial we will be using an all-in-one installation of Mesos/Marathon/Chronos. This is the docker compose file used to setup the mini-cluster: version : '3.7' services : zookeeper : image : indigodatacloud/zookeeper expose : - 2181 environment : - MYID=1 - SERVERS=localhost volumes : - ./var/log/zookeeper:/var/log/zookeeper - ./var/lib/zookeeper:/var/lib/zookeeper mesosmaster : image : marica/mesos-master:1.11.0 ports : - 5050:5050 environment : - MESOS_HOSTNAME=192.168.28.196 - MESOS_CLUSTER=Mesos - MESOS_ZK=zk://zookeeper:2181/mesos - MESOS_LOG_DIR=/var/log/mesos - MESOS_QUORUM=1 - MESOS_WORK_DIR=/var/lib/mesos - MESOS_OFFER_TIMEOUT=30secs volumes : - ./var/log/mesos:/var/log/mesos - ./var/lib/mesos:/var/lib/mesos depends_on : - zookeeper mesosslave : image : marica/mesos-agent:1.11.0 ports : - 5051:5051 pid : host privileged : true environment : MESOS_MASTER : zk://zookeeper:2181/mesos MESOS_CONTAINERIZERS : docker,mesos MESOS_PORT : 5051 MESOS_RESOURCES : ports(*):[11000-11999] MESOS_WORK_DIR : /tmp/mesos MESOS_HOSTNAME : 192.168.28.196 volumes : - /sys/fs/cgroup:/sys/fs/cgroup - /var/run/docker.sock:/var/run/docker.sock - /tmp/mesos:/tmp/mesos - ./var/log/mesos:/var/log/mesos depends_on : - zookeeper - mesosmaster chronos : image : indigodatacloud/chronos:3.0.2_gpu ports : - 4400:4400 environment : - CHRONOS_HOSTNAME=192.168.28.196 - CHRONOS_HTTP_PORT=4400 - CHRONOS_MASTER=zk://zookeeper:2181/mesos - CHRONOS_ZK_HOSTS=zk://zookeeper:2181 - CHRONOS_ZK_PATH=/chronos/state - CHRONOS_MESOS_FRAMEWORK_NAME=chronos depends_on : - zookeeper - mesosmaster marathon : image : marica/marathon:1.8.244 ports : - 8080:8080 environment : - MARATHON_HOSTNAME=192.168.28.196 - MARATHON_HTTP_PORT=8080 - MARATHON_MASTER=zk://zookeeper:2181/mesos - MARATHON_ZK=zk://zookeeper:2181/marathon - MARATHON_FRAMEWORK_NAME=marathon depends_on : - zookeeper - mesosmaster marathon_lb : image : mesosphere/marathon-lb:v1.14.1 command : sse --marathon http://marathon:8080 --group external ports : - \"10000-10100:10000-10100\" environment : - PORTS=9090 depends_on : - marathon Start the cluster: cd /opt/mesos docker-compose up -d Check that the services are up and running: docker-compose ps Name Command State Ports ------------------------------------------------------------------------------------------------------- mesos_chronos_1 /entrypoint.sh Up 0 .0.0.0:4400->4400/tcp,:::4400->4400/tcp mesos_marathon_1 /entrypoint.sh marathon Up 0 .0.0.0:8080->8080/tcp,:::8080->8080/tcp mesos_mesosmaster_1 /entrypoint.sh /usr/sbin/m ... Up 0 .0.0.0:5050->5050/tcp,:::5050->5050/tcp mesos_mesosslave_1 /entrypoint.sh /usr/sbin/m ... Up 0 .0.0.0:5051->5051/tcp,:::5051->5051/tcp mesos_zookeeper_1 /entrypoint.sh /usr/share/ ... Up 2181 /tcp Use your browser to connect to Mesos on port 5050 of your machine: Tip Use the following command to get the ip of your VM: ip a show ens3 Open a new tab of your browser and connect to Marathon on port 8080 of your machine: Finally in another tab connect to Chronos on port 4400 of your machine:","title":"Description of the mini-cluster"},{"location":"marathon/","text":"Using Marathon web UI \u00b6 Now, let\u2019s start using the Marathon GUI. Click on Create Application : We are presented with a window in which we can name and configure an application to run in Marathon. Let's try to deploy the application packaged in the nginxdemos/hello docker image. Note This image allows to run a NGINX webserver that serves a simple page containing its hostname, IP address and port as wells as the request URI and the local time of the webserver. Change the Network field value to Bridged : and specify the port 80 in the Ports tab in order to map the container port 80 (where nginx is listening inside the container) to a host port. Note that if you click on the Json Mode switch on the top right corner of the Application window you can see the json definition of your application: Then click on Create Application . In a few moments you will see your application running. Click on the name of the application in order to access the application details and menu: Under the instances tab you can see the ID of your application instance and the IP:port URL to access the deployed service. Click on it and you will access the demo web server: Now move to the Mesos web UI (port 5050 ): you can see your running container under the Active Tasks window: Clicking on the Sandbox link you will browse the container sandbox and read the stdout and stderr files: Finally you can destroy your application: Scaling and load-balancing \u00b6 Reference Take a look at the official docs: https://mesosphere.github.io/marathon/docs/service-discovery-load-balancing.html When your app is up and running, you need a way to send traffic to it, from other applications on the same cluster, and from external clients. In your mini-cluster Marathon-lb provides port-based service discovery using HAProxy , a lightweight TCP/HTTP proxy. Adding the label HAPROXY_GROUP=external to your application, you will expose your app on the Load Balancer (LB): services are exposed on their service port as defined in their Marathon definition. Let's create again our application from nginxdemos/hello docker image, but this time we will add the label HAPROXY_GROUP : Looking at the app Configuration we can see the service port assigned to our service (in this case it was 10000 ). Connect to the service port on your host: you will see the web server main page. Now let's scale our application in order to have 2 instances of the web server: As you can see now we have two running docker containers, using two different host ports (11436 and 11849), but we can still use the service port 10000 managed by our Marathon-lb : client requests will be forwarded to each instance in turn. You can verify that using the following command: curl --silent \"http://192.168.28.151:10000\" | grep 'name' Warning Replace the IP 192.168.28.151 with your VM IP and the port 10000 with the service port shown in the application Configuration tab. You will see the following behaviour showing that the requests are managed by the two containers in turn: Marathon REST API \u00b6 The following table reports the main API endpoints: API Endpoint Description /v2/deployments Query for all running deployments on a Marathon instance ('GET') /v2/deployments/ Query for information about a specific deployment ( GET ) /v2/apps Query for all applications on a Marathon instance ( GET ) or create new applications ( POST ) /v2/apps/ Query for information about a specific app ( GET ), update the configuration of an app ( PUT ), or delete an app ( DELETE ) /v2/groups Query for all application groups on a Marathon instance ( GET ) or create a new application group ( POST ) /v2/groups/ Query for information about a specific application group ( GET ), update the configuration of an application group ( PUT ), or delete an application group ( DELETE ) We will be using these endpoints in the following sections. Application groups \u00b6 Application groups are used to partition applications into disjoint sets for management. Groups make it easy to manage logically related applications and allow you to perform actions on the entire group, such as scaling. Marathon takes dependencies into account while starting, stopping, upgrading and scaling. Here is the json definition of this application group: Warning Replace the value of the env var PMA_HOST at line 52 with your VM IP. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 { \"id\" : \"/dbaas\" , \"apps\" : [ { \"id\" : \"/dbaas/db\" , \"container\" : { \"type\" : \"DOCKER\" , \"docker\" : { \"image\" : \"mariadb:10.3\" , \"network\" : \"BRIDGE\" , \"portMappings\" : [ { \"containerPort\" : 3306 , \"servicePort\" : 10006 , \"protocol\" : \"tcp\" } ] } }, \"env\" : { \"MYSQL_ROOT_PASSWORD\" : \"s3cret\" , \"MYSQL_USER\" : \"phpma\" , \"MYSQL_PASSWORD\" : \"s3cret\" }, \"labels\" : { \"HAPROXY_GROUP\" : \"external\" }, \"instances\" : 1 , \"cpus\" : 0.5 , \"mem\" : 512 }, { \"id\" : \"/dbaas/phpmyadmin\" , \"container\" : { \"type\" : \"DOCKER\" , \"docker\" : { \"image\" : \"phpmyadmin/phpmyadmin\" , \"network\" : \"BRIDGE\" , \"portMappings\" : [ { \"containerPort\" : 80 , \"servicePort\" : 10008 , \"protocol\" : \"tcp\" } ] } }, \"dependencies\" : [ \"/dbaas/db\" ], \"env\" : { \"PMA_HOST\" : \"192.168.28.151\" , \"PMA_PORT\" : \"10006\" }, \"labels\" : { \"HAPROXY_GROUP\" : \"external\" }, \"instances\" : 1 , \"cpus\" : 0.1 , \"mem\" : 256 } ] } Look at the definition of the application group: in both applications we have set some environment variables (json tag env ): MYSQL_ROOT_PASSWORD , MYSQL_USER , MYSQL_PASSWORD are set for the first application db : these environment variables are required by the Official mariadb docker image; PMA_HOST , PMA_PORT are set for the second application phpmyadmin : these environment variables are required by the Official phpmyadmin docker image. the phpmyadmin app depends on the db app: the dependency is defined at lines 48-50 this services communicates with the db using the service port (10006) defined at line 14. Save the json above in a file, e.g. dbaas.json , and deploy it using the /v2/groups endpoint: curl -H 'Content-Type: application/json' -X POST http://localhost:8080/v2/groups -d@dbaas.json Through the Marathon web UI you can monitor your deployment: Click on the dbaas folder to see the applications of the group: When they are running you will be able to access the phpmyadmin web tool on port 10008 of your VM: Use the root credentials to access the administrative panel of the DBMS (username root, password as set in the json at line ): Let's create a new database test : The new database has been stored in the db container...What happens if you restart the db app? Click on button Restart in the db application menu: Marathon creates a new instance of our application, that means a new container; once the new container is up and running the old one is destroyed. Since the database test was stored in the old container, we lose our data: Using local storage \u00b6 Modify the json definition of the db application to request a volume: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 { \"id\" : \"/dbaas\" , \"apps\" : [ { \"id\" : \"/dbaas/db\" , \"container\" : { \"type\" : \"DOCKER\" , \"docker\" : { \"image\" : \"mariadb:10.3\" , \"network\" : \"BRIDGE\" , \"portMappings\" : [ { \"containerPort\" : 3306 , \"servicePort\" : 10006 , \"protocol\" : \"tcp\" } ] } , \"volumes\" : [ { \"containerPath\" : \"/var/lib/mysql\" , \"mode\" : \"RW\" , \"hostPath\" : \"/tmp/mysql\" } ] } , \"env\" : { \"MYSQL_ROOT_PASSWORD\" : \"s3cret\" , \"MYSQL_USER\" : \"phpma\" , \"MYSQL_PASSWORD\" : \"s3cret\" } , \"labels\" : { \"HAPROXY_GROUP\" : \"external\" } , \"instances\" : 1 , \"cpus\" : 0 .5, \"mem\" : 512 } , { \"id\" : \"/dbaas/phpmyadmin\" , \"container\" : { \"type\" : \"DOCKER\" , \"docker\" : { \"image\" : \"phpmyadmin/phpmyadmin\" , \"network\" : \"BRIDGE\" , \"portMappings\" : [ { \"containerPort\" : 80 , \"servicePort\" : 10008 , \"protocol\" : \"tcp\" } ] } } , \"dependencies\" : [ \"/dbaas/db\" ] , \"env\" : { \"PMA_HOST\" : \"192.168.28.151\" , \"PMA_PORT\" : \"10006\" } , \"labels\" : { \"HAPROXY_GROUP\" : \"external\" } , \"instances\" : 1 , \"cpus\" : 0 .1, \"mem\" : 256 } ] } Lines 19-25 define a bind-mount volume: docker inspect $( docker ps -q --filter ancestor = mariadb:10.3 ) ... \"Binds\" : [ \"/tmp/mysql:/var/lib/mysql:rw\" , \"/tmp/mesos/slaves/692a979a-a998-4dd4-b059-8da9bfdf706d-S0/frameworks/692a979a-a998-4dd4-b059-8da9bfdf706d-0001/executors/dbaas_db.cb02ea99-cc5e-11eb-b551-0242ac140004/runs/34b09a76-9558-4429-bf56-61aeb8d0713a:/mnt/mesos/sandbox\" ] , ... Update your deployment with a PUT request: curl -H 'Content-Type: application/json' -X PUT http://localhost:8080/v2/groups -d@dbaas.json Now repeat the steps describe above: create a database and then restart the db application (you can use the Marathon web ui). The database will survive if the db container is re-created. Note that this is not sufficient to ensure data persistence for your applications. In a multi-node cluster, if the node where your container is running fails, it will be re-deployed on another node and it will not find the data stored previously. In order to make your apps more fault-tolerant, you can use an external storage service, such as Ceph or Amazon EBS, to create a persistent volume that follows your application instance. This topic is beyond the scope of this basic tutorial. See the docs for more details. Health checks \u00b6 Using the web UI click on the Health Checks tab to setup your checks: Using the REST APIs add the healthChecks definition in the application json as in the following example: { \"id\" : \"nginx\" , \"cpus\" : 0 .25, \"mem\" : 128 , \"disk\" : 0 , \"instances\" : 1 , \"container\" : { \"docker\" : { \"image\" : \"nginx\" } , \"type\" : \"DOCKER\" , \"portMappings\" : [ { \"containerPort\" : 80 , \"protocol\" : \"tcp\" } ] } , \"networks\" : [ { \"mode\" : \"container/bridge\" } ] , \"healthChecks\" : [ { \"protocol\" : \"HTTP\" , \"path\" : \"/\" , \"portIndex\" : 0 , \"gracePeriodSeconds\" : 300 , \"intervalSeconds\" : 60 , \"timeoutSeconds\" : 20 , \"maxConsecutiveFailures\" : 3 } ] } If the checks are passed, the application status will be healthy and you will get a green bar near your instance:","title":"Deploy long running services on Marathon"},{"location":"marathon/#using-marathon-web-ui","text":"Now, let\u2019s start using the Marathon GUI. Click on Create Application : We are presented with a window in which we can name and configure an application to run in Marathon. Let's try to deploy the application packaged in the nginxdemos/hello docker image. Note This image allows to run a NGINX webserver that serves a simple page containing its hostname, IP address and port as wells as the request URI and the local time of the webserver. Change the Network field value to Bridged : and specify the port 80 in the Ports tab in order to map the container port 80 (where nginx is listening inside the container) to a host port. Note that if you click on the Json Mode switch on the top right corner of the Application window you can see the json definition of your application: Then click on Create Application . In a few moments you will see your application running. Click on the name of the application in order to access the application details and menu: Under the instances tab you can see the ID of your application instance and the IP:port URL to access the deployed service. Click on it and you will access the demo web server: Now move to the Mesos web UI (port 5050 ): you can see your running container under the Active Tasks window: Clicking on the Sandbox link you will browse the container sandbox and read the stdout and stderr files: Finally you can destroy your application:","title":"Using Marathon web UI"},{"location":"marathon/#scaling-and-load-balancing","text":"Reference Take a look at the official docs: https://mesosphere.github.io/marathon/docs/service-discovery-load-balancing.html When your app is up and running, you need a way to send traffic to it, from other applications on the same cluster, and from external clients. In your mini-cluster Marathon-lb provides port-based service discovery using HAProxy , a lightweight TCP/HTTP proxy. Adding the label HAPROXY_GROUP=external to your application, you will expose your app on the Load Balancer (LB): services are exposed on their service port as defined in their Marathon definition. Let's create again our application from nginxdemos/hello docker image, but this time we will add the label HAPROXY_GROUP : Looking at the app Configuration we can see the service port assigned to our service (in this case it was 10000 ). Connect to the service port on your host: you will see the web server main page. Now let's scale our application in order to have 2 instances of the web server: As you can see now we have two running docker containers, using two different host ports (11436 and 11849), but we can still use the service port 10000 managed by our Marathon-lb : client requests will be forwarded to each instance in turn. You can verify that using the following command: curl --silent \"http://192.168.28.151:10000\" | grep 'name' Warning Replace the IP 192.168.28.151 with your VM IP and the port 10000 with the service port shown in the application Configuration tab. You will see the following behaviour showing that the requests are managed by the two containers in turn:","title":"Scaling and load-balancing"},{"location":"marathon/#marathon-rest-api","text":"The following table reports the main API endpoints: API Endpoint Description /v2/deployments Query for all running deployments on a Marathon instance ('GET') /v2/deployments/ Query for information about a specific deployment ( GET ) /v2/apps Query for all applications on a Marathon instance ( GET ) or create new applications ( POST ) /v2/apps/ Query for information about a specific app ( GET ), update the configuration of an app ( PUT ), or delete an app ( DELETE ) /v2/groups Query for all application groups on a Marathon instance ( GET ) or create a new application group ( POST ) /v2/groups/ Query for information about a specific application group ( GET ), update the configuration of an application group ( PUT ), or delete an application group ( DELETE ) We will be using these endpoints in the following sections.","title":"Marathon REST API"},{"location":"marathon/#application-groups","text":"Application groups are used to partition applications into disjoint sets for management. Groups make it easy to manage logically related applications and allow you to perform actions on the entire group, such as scaling. Marathon takes dependencies into account while starting, stopping, upgrading and scaling. Here is the json definition of this application group: Warning Replace the value of the env var PMA_HOST at line 52 with your VM IP. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 { \"id\" : \"/dbaas\" , \"apps\" : [ { \"id\" : \"/dbaas/db\" , \"container\" : { \"type\" : \"DOCKER\" , \"docker\" : { \"image\" : \"mariadb:10.3\" , \"network\" : \"BRIDGE\" , \"portMappings\" : [ { \"containerPort\" : 3306 , \"servicePort\" : 10006 , \"protocol\" : \"tcp\" } ] } }, \"env\" : { \"MYSQL_ROOT_PASSWORD\" : \"s3cret\" , \"MYSQL_USER\" : \"phpma\" , \"MYSQL_PASSWORD\" : \"s3cret\" }, \"labels\" : { \"HAPROXY_GROUP\" : \"external\" }, \"instances\" : 1 , \"cpus\" : 0.5 , \"mem\" : 512 }, { \"id\" : \"/dbaas/phpmyadmin\" , \"container\" : { \"type\" : \"DOCKER\" , \"docker\" : { \"image\" : \"phpmyadmin/phpmyadmin\" , \"network\" : \"BRIDGE\" , \"portMappings\" : [ { \"containerPort\" : 80 , \"servicePort\" : 10008 , \"protocol\" : \"tcp\" } ] } }, \"dependencies\" : [ \"/dbaas/db\" ], \"env\" : { \"PMA_HOST\" : \"192.168.28.151\" , \"PMA_PORT\" : \"10006\" }, \"labels\" : { \"HAPROXY_GROUP\" : \"external\" }, \"instances\" : 1 , \"cpus\" : 0.1 , \"mem\" : 256 } ] } Look at the definition of the application group: in both applications we have set some environment variables (json tag env ): MYSQL_ROOT_PASSWORD , MYSQL_USER , MYSQL_PASSWORD are set for the first application db : these environment variables are required by the Official mariadb docker image; PMA_HOST , PMA_PORT are set for the second application phpmyadmin : these environment variables are required by the Official phpmyadmin docker image. the phpmyadmin app depends on the db app: the dependency is defined at lines 48-50 this services communicates with the db using the service port (10006) defined at line 14. Save the json above in a file, e.g. dbaas.json , and deploy it using the /v2/groups endpoint: curl -H 'Content-Type: application/json' -X POST http://localhost:8080/v2/groups -d@dbaas.json Through the Marathon web UI you can monitor your deployment: Click on the dbaas folder to see the applications of the group: When they are running you will be able to access the phpmyadmin web tool on port 10008 of your VM: Use the root credentials to access the administrative panel of the DBMS (username root, password as set in the json at line ): Let's create a new database test : The new database has been stored in the db container...What happens if you restart the db app? Click on button Restart in the db application menu: Marathon creates a new instance of our application, that means a new container; once the new container is up and running the old one is destroyed. Since the database test was stored in the old container, we lose our data:","title":"Application groups"},{"location":"marathon/#using-local-storage","text":"Modify the json definition of the db application to request a volume: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 { \"id\" : \"/dbaas\" , \"apps\" : [ { \"id\" : \"/dbaas/db\" , \"container\" : { \"type\" : \"DOCKER\" , \"docker\" : { \"image\" : \"mariadb:10.3\" , \"network\" : \"BRIDGE\" , \"portMappings\" : [ { \"containerPort\" : 3306 , \"servicePort\" : 10006 , \"protocol\" : \"tcp\" } ] } , \"volumes\" : [ { \"containerPath\" : \"/var/lib/mysql\" , \"mode\" : \"RW\" , \"hostPath\" : \"/tmp/mysql\" } ] } , \"env\" : { \"MYSQL_ROOT_PASSWORD\" : \"s3cret\" , \"MYSQL_USER\" : \"phpma\" , \"MYSQL_PASSWORD\" : \"s3cret\" } , \"labels\" : { \"HAPROXY_GROUP\" : \"external\" } , \"instances\" : 1 , \"cpus\" : 0 .5, \"mem\" : 512 } , { \"id\" : \"/dbaas/phpmyadmin\" , \"container\" : { \"type\" : \"DOCKER\" , \"docker\" : { \"image\" : \"phpmyadmin/phpmyadmin\" , \"network\" : \"BRIDGE\" , \"portMappings\" : [ { \"containerPort\" : 80 , \"servicePort\" : 10008 , \"protocol\" : \"tcp\" } ] } } , \"dependencies\" : [ \"/dbaas/db\" ] , \"env\" : { \"PMA_HOST\" : \"192.168.28.151\" , \"PMA_PORT\" : \"10006\" } , \"labels\" : { \"HAPROXY_GROUP\" : \"external\" } , \"instances\" : 1 , \"cpus\" : 0 .1, \"mem\" : 256 } ] } Lines 19-25 define a bind-mount volume: docker inspect $( docker ps -q --filter ancestor = mariadb:10.3 ) ... \"Binds\" : [ \"/tmp/mysql:/var/lib/mysql:rw\" , \"/tmp/mesos/slaves/692a979a-a998-4dd4-b059-8da9bfdf706d-S0/frameworks/692a979a-a998-4dd4-b059-8da9bfdf706d-0001/executors/dbaas_db.cb02ea99-cc5e-11eb-b551-0242ac140004/runs/34b09a76-9558-4429-bf56-61aeb8d0713a:/mnt/mesos/sandbox\" ] , ... Update your deployment with a PUT request: curl -H 'Content-Type: application/json' -X PUT http://localhost:8080/v2/groups -d@dbaas.json Now repeat the steps describe above: create a database and then restart the db application (you can use the Marathon web ui). The database will survive if the db container is re-created. Note that this is not sufficient to ensure data persistence for your applications. In a multi-node cluster, if the node where your container is running fails, it will be re-deployed on another node and it will not find the data stored previously. In order to make your apps more fault-tolerant, you can use an external storage service, such as Ceph or Amazon EBS, to create a persistent volume that follows your application instance. This topic is beyond the scope of this basic tutorial. See the docs for more details.","title":"Using local storage"},{"location":"marathon/#health-checks","text":"Using the web UI click on the Health Checks tab to setup your checks: Using the REST APIs add the healthChecks definition in the application json as in the following example: { \"id\" : \"nginx\" , \"cpus\" : 0 .25, \"mem\" : 128 , \"disk\" : 0 , \"instances\" : 1 , \"container\" : { \"docker\" : { \"image\" : \"nginx\" } , \"type\" : \"DOCKER\" , \"portMappings\" : [ { \"containerPort\" : 80 , \"protocol\" : \"tcp\" } ] } , \"networks\" : [ { \"mode\" : \"container/bridge\" } ] , \"healthChecks\" : [ { \"protocol\" : \"HTTP\" , \"path\" : \"/\" , \"portIndex\" : 0 , \"gracePeriodSeconds\" : 300 , \"intervalSeconds\" : 60 , \"timeoutSeconds\" : 20 , \"maxConsecutiveFailures\" : 3 } ] } If the checks are passed, the application status will be healthy and you will get a green bar near your instance:","title":"Health checks"}]}